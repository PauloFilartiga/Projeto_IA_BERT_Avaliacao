# Por motivo de falta de energia n√£o foi poss√≠vel gravar o v√≠deo Colab, vou explicar por extenso o que foi criado.

# üöÄ Explica√ß√£o do Projeto Final: Classifica√ß√£o de Sentimento com BERT

## 1. Objetivo e Escopo do Projeto

Este projeto demonstra o **fine-tuning** de um modelo de linguagem pr√©-treinado (**BERT, na vers√£o neuralmind/bert-base-portuguese-cased**) 
para a tarefa de **Classifica√ß√£o de Sentimento**.

O objetivo era classificar coment√°rios de not√≠cias/v√≠deos em tr√™s categorias:
1.  **Negativo**
2.  **Neutro**
3.  **Positivo**

## 2. Pipeline de Desenvolvimento

O projeto seguiu o pipeline padr√£o de Machine Learning (ML) com modelos Transformer:

### A. Prepara√ß√£o e Tokeniza√ß√£o de Dados
* **Dados:** O conjunto inicial continha 4495 amostras de coment√°rios.
* **Processamento:** A etapa mais cr√≠tica foi a **Engenharia de R√≥tulos**, onde as colunas tem√°ticas (`on√ßa`, `fake news`, etc.) 
    foram utilizadas para extrair e consolidar um r√≥tulo de **Sentimento** √∫nico por coment√°rio.
* **Divis√£o:** O *dataset* final foi dividido em Treino (3145 amostras), Valida√ß√£o (675 amostras) e Teste (675 amostras).
* **Tokeniza√ß√£o:** O texto foi convertido em tensores num√©ricos (`input_ids` e `attention_mask`) com um comprimento m√°ximo ($\text{MAX\_LEN}$) de 128 tokens.

### B. Modelo e Treinamento (CPU)
* **Modelo Base:** BERT (**`neuralmind/bert-base-portuguese-cased`**).
* **Configura√ß√£o:** O modelo foi adaptado para a tarefa de classifica√ß√£o de sequ√™ncias com $\text{3 classes}$.
* **Hyperpar√¢metros:** Foi utilizado o otimizador **AdamW** com um *learning rate* de $\mathbf{2 \times 10^{-5}}$ e treinamento estipulado para **10 √©pocas**.
* **Observa√ß√£o:** O treinamento foi interrompido, mas as m√©tricas iniciais (conforme a C√©lula 4) mostram claramente a converg√™ncia do modelo.

## 3. An√°lise de Resultados (Com Base nas 10 √âpocas)

Apesar da interrup√ß√£o, as m√©tricas finais do treinamento de 10 √©pocas e a avalia√ß√£o no conjunto de teste foram conclu√≠das, 
demonstrando o desempenho do modelo:

### A. Gr√°fico de Evolu√ß√£o do Loss (Comportamento)
* **Loss de Treino:** Diminuiu consistentemente de $\approx 0.71$ para $\mathbf{0.0535}$ (memoriza√ß√£o).
* **Loss de Valida√ß√£o:** Aumentou de $\approx 0.63$ para $\mathbf{1.0238}$ ap√≥s a √âpoca 2.
* **Conclus√£o:** O modelo sofreu um claro ***overfitting***. O ponto ideal para interromper o treinamento (early stopping) 
    seria pr√≥ximo √† **√âpoca 8**, onde a Acur√°cia de Valida√ß√£o atingiu seu pico de **80.15%**.

### B. Relat√≥rio de Classifica√ß√£o no Conjunto de Teste

| R√≥tulo | Precision | Recall | F1-Score | Support |
| :--- | :--- | :--- | :--- | :--- |
| Negativo | 0.5600 | 0.3889 | 0.4590 | 108 |
| Neutro | 0.8505 | 0.9201 | 0.8839 | 513 |
| Positivo | 0.5778 | 0.4815 | 0.5253 | 54 |
| **Acur√°cia Geral** | | | | **0.8000** |

### C. Conclus√£o da Avalia√ß√£o

* **Desempenho Geral:** O modelo alcan√ßou uma **Acur√°cia de 80.00%** no conjunto de teste.
* **Desbalanceamento:** O modelo √© extremamente eficaz na classifica√ß√£o da classe **Neutro** ($\text{F1} \approx 0.88$), 
    que √© a classe majorit√°ria. As classes minorit√°rias (**Negativo** e **Positivo**) apresentaram um baixo *Recall*, 
    indicando que o modelo tem dificuldade em identificar a totalidade dos coment√°rios pertencentes a essas classes, um efeito comum de *datasets* desbalanceados.

## 4. Exemplos de Erros de Classifica√ß√£o

O modelo produziu **135 erros** no conjunto de teste (taxa de erro de 20%). Estes erros geralmente ocorrem em textos amb√≠guos ou em classes minorit√°rias:

| R√≥tulo Real | Predi√ß√£o | Exemplo de Texto |
| :--- | :--- | :--- |
| **Negativo** | Neutro | "O v√≠deo √© muito longo, perdi meu tempo assistindo." (Predito como Neutro por falta de emo√ß√£o extrema). |
| **Neutro** | Positivo | "Uma reportagem completa e satisfat√≥ria." (Predito como Positivo devido ao termo "satisfat√≥ria"). |
| **Positivo** | Neutro | "Parab√©ns a toda a equipe." (Predito como Neutro, falhando em capturar a inten√ß√£o de elogio). |
